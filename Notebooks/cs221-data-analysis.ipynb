{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8212188,"sourceType":"datasetVersion","datasetId":4689763}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries + data\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Train:\ntrain = pd.read_csv(\"/kaggle/input/homomex24-development/public_data_train_phase/track_1_train.csv\")\ntrain2 = pd.read_csv(\"/kaggle/input/homomex24-development/public_data_train_phase/track_2_train.csv\")\ntrain3 = pd.read_csv(\"/kaggle/input/homomex24-development/public_data_train_phase/track_3_train.csv\")\n\n# Dev:\ndev = pd.read_csv(\"/kaggle/input/homomex24-development/track_1_dev.csv\")\ndev2 = pd.read_csv(\"/kaggle/input/homomex24-development/track_2_dev.csv\")\ndev3 = pd.read_csv(\"/kaggle/input/homomex24-development/track_3_dev.csv\")\n# Test:\ntest = pd.read_csv(\"/kaggle/input/homomex24-development/public_data_test/track_1_public_test.csv\")\ntest2 = pd.read_csv(\"/kaggle/input/homomex24-development/public_data_test/track_2_public_test.csv\")\ntest3 = pd.read_csv(\"/kaggle/input/homomex24-development/public_data_test/track_3_public_test.csv\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T18:24:36.315798Z","iopub.execute_input":"2024-05-20T18:24:36.316220Z","iopub.status.idle":"2024-05-20T18:24:36.504233Z","shell.execute_reply.started":"2024-05-20T18:24:36.316189Z","shell.execute_reply":"2024-05-20T18:24:36.503057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Corpus","metadata":{}},{"cell_type":"code","source":"# Thống kê chiều dài\ntrain[\"length\"] = train[\"content\"].apply(len)\nmax_length = train[\"length\"].max()\nmin_length = train[\"length\"].min()\navg_length = train[\"length\"].mean()\n\n# Thống kê số token\ntrain[\"tokens\"] = train[\"content\"].apply(lambda x: x.split())\nnum_tokens = train[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(train[\"tokens\"].sum()))\n\n# Phân bố lớp\nclass_counts = train[\"label\"].value_counts()\n\n# Hiển thị kết quả\nprint(\"## Thống kê dữ liệu file track_1_QAtrain.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\nprint(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:36.506199Z","iopub.execute_input":"2024-05-20T18:24:36.506653Z","iopub.status.idle":"2024-05-20T18:24:43.659209Z","shell.execute_reply.started":"2024-05-20T18:24:36.506623Z","shell.execute_reply":"2024-05-20T18:24:43.657730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thống kê chiều dài\ntrain2[\"length\"] = train2[\"content\"].apply(len)\nmax_length = train2[\"length\"].max()\nmin_length = train2[\"length\"].min()\navg_length = train2[\"length\"].mean()\n\n# Thống kê số token\ntrain2[\"tokens\"] = train2[\"content\"].apply(lambda x: x.split())\nnum_tokens = train2[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(train2[\"tokens\"].sum()))\n\n\n# Hiển thị kết quả\nprint(\"## Thống kê dữ liệu file track_2_train.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\ntrain2 = train2.drop(\"length\", axis=1)\ntrain2 = train2.drop(\"tokens\", axis=1)\nfor col in train2.columns:\n    if col != \"content\":\n        # Đếm số lượng giá trị \"1\" trong cột\n        num_ones = train2[col].value_counts().get(1, 0)\n\n        print(f\"- \\\"{col}\\\":\", num_ones)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:43.660539Z","iopub.execute_input":"2024-05-20T18:24:43.660875Z","iopub.status.idle":"2024-05-20T18:24:43.746231Z","shell.execute_reply.started":"2024-05-20T18:24:43.660846Z","shell.execute_reply":"2024-05-20T18:24:43.745057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thống kê chiều dài\ntrain3[\"length\"] = train3[\"lyrics\"].apply(len)\nmax_length = train3[\"length\"].max()\nmin_length = train3[\"length\"].min()\navg_length = train3[\"length\"].mean()\n\n# Thống kê số token\ntrain3[\"tokens\"] = train3[\"lyrics\"].apply(lambda x: x.split())\nnum_tokens = train3[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(train3[\"tokens\"].sum()))\n\n# Phân bố lớp\nclass_counts = train3[\"label\"].value_counts()\n\n# Hiển thị kết quả\nprint(\"## Thống kê dữ liệu file track_3_train.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\nprint(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:43.749094Z","iopub.execute_input":"2024-05-20T18:24:43.749474Z","iopub.status.idle":"2024-05-20T18:24:45.922789Z","shell.execute_reply.started":"2024-05-20T18:24:43.749444Z","shell.execute_reply":"2024-05-20T18:24:45.921508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dev Corpus\n","metadata":{}},{"cell_type":"code","source":"dev[\"length\"] = dev[\"content\"].apply(len)\nmax_length = train[\"length\"].max()\nmin_length = train[\"length\"].min()\navg_length = train[\"length\"].mean()\ntrain[\"tokens\"] = train[\"content\"].apply(lambda x: x.split())\nnum_tokens = train[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(train[\"tokens\"].sum()))\nclass_counts = train[\"label\"].value_counts()\n\nprint(\"## Thống kê dữ liệu file track_1_dev.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\nprint(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:45.923828Z","iopub.execute_input":"2024-05-20T18:24:45.924167Z","iopub.status.idle":"2024-05-20T18:24:52.460534Z","shell.execute_reply.started":"2024-05-20T18:24:45.924139Z","shell.execute_reply":"2024-05-20T18:24:52.459262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev2[\"length\"] = dev2[\"content\"].apply(len)\nmax_length = dev2[\"length\"].max()\nmin_length = dev2[\"length\"].min()\navg_length = dev2[\"length\"].mean()\ndev2[\"tokens\"] = dev2[\"content\"].apply(lambda x: x.split())\nnum_tokens = dev2[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(dev2[\"tokens\"].sum()))\n\nprint(\"## Thống kê dữ liệu file track_2_dev.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\ndev2 = dev2.drop(\"length\", axis=1)\ndev2 = dev2.drop(\"tokens\", axis=1)\nfor col in dev2.columns:\n    if col != \"content\":\n        # Đếm số lượng giá trị \"1\" trong cột\n        num_ones = dev2[col].value_counts().get(1, 0)\n\n        print(f\"- \\\"{col}\\\":\", num_ones)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:52.462089Z","iopub.execute_input":"2024-05-20T18:24:52.462544Z","iopub.status.idle":"2024-05-20T18:24:52.530666Z","shell.execute_reply.started":"2024-05-20T18:24:52.462498Z","shell.execute_reply":"2024-05-20T18:24:52.528696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dev3[\"length\"] = dev3[\"lyric\"].apply(len)\nmax_length = dev3[\"length\"].max()\nmin_length = dev3[\"length\"].min()\navg_length = dev3[\"length\"].mean()\ndev3[\"tokens\"] = dev3[\"lyric\"].apply(lambda x: x.split())\nnum_tokens = dev3[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(dev3[\"tokens\"].sum()))\nclass_counts = dev3[\"label\"].value_counts()\n\nprint(\"## Thống kê dữ liệu file track_3_dev3.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\nprint(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:52.532494Z","iopub.execute_input":"2024-05-20T18:24:52.533082Z","iopub.status.idle":"2024-05-20T18:24:53.111214Z","shell.execute_reply.started":"2024-05-20T18:24:52.533036Z","shell.execute_reply":"2024-05-20T18:24:53.109977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test corpus","metadata":{}},{"cell_type":"code","source":"test[\"length\"] = test[\"content\"].apply(len)\nmax_length = test[\"length\"].max()\nmin_length = test[\"length\"].min()\navg_length = test[\"length\"].mean()\ntest[\"tokens\"] = test[\"content\"].apply(lambda x: x.split())\nnum_tokens = test[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(test[\"tokens\"].sum()))\n#class_counts = train[\"label\"].value_counts()\n\nprint(\"## Thống kê dữ liệu file track_1_test.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\n# print(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:53.115253Z","iopub.execute_input":"2024-05-20T18:24:53.115600Z","iopub.status.idle":"2024-05-20T18:24:53.559200Z","shell.execute_reply.started":"2024-05-20T18:24:53.115572Z","shell.execute_reply":"2024-05-20T18:24:53.557718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test2[\"length\"] = test2[\"content\"].apply(len)\nmax_length = test2[\"length\"].max()\nmin_length = test2[\"length\"].min()\navg_length = test2[\"length\"].mean()\ntest2[\"tokens\"] = test2[\"content\"].apply(lambda x: x.split())\nnum_tokens = test2[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(test2[\"tokens\"].sum()))\n\nprint(\"## Thống kê dữ liệu file track_2_train.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\n# test2 = test2.drop(\"length\", axis=1)\n# test2 = test2.drop(\"tokens\", axis=1)\n# for col in test2.columns:\n#     if col != \"content\":\n#         # Đếm số lượng giá trị \"1\" trong cột\n#         num_ones = test2[col].value_counts().get(1, 0)\n\n#         print(f\"- \\\"{col}\\\":\", num_ones)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:53.560674Z","iopub.execute_input":"2024-05-20T18:24:53.561139Z","iopub.status.idle":"2024-05-20T18:24:53.590104Z","shell.execute_reply.started":"2024-05-20T18:24:53.561099Z","shell.execute_reply":"2024-05-20T18:24:53.588985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train3[\"length\"] = train3[\"lyrics\"].apply(len)\nmax_length = train3[\"length\"].max()\nmin_length = train3[\"length\"].min()\navg_length = train3[\"length\"].mean()\ntrain3[\"tokens\"] = train3[\"lyrics\"].apply(lambda x: x.split())\nnum_tokens = train3[\"tokens\"].apply(len).sum()\nnum_vocab = len(set(train3[\"tokens\"].sum()))\n# class_counts = train3[\"label\"].value_counts()\n\n# Hiển thị kết quả\nprint(\"## Thống kê dữ liệu file track_3_train.csv\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Min length: {min_length}\")\nprint(f\"Average length: {avg_length:.2f}\")\nprint(f\"Number of tokens: {num_tokens}\")\nprint(f\"Number of vocabulary: {num_vocab}\")\nprint(f\"Class distribution:\")\n# print(class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-20T18:24:53.594630Z","iopub.execute_input":"2024-05-20T18:24:53.595286Z","iopub.status.idle":"2024-05-20T18:24:55.656112Z","shell.execute_reply.started":"2024-05-20T18:24:53.595248Z","shell.execute_reply":"2024-05-20T18:24:55.654947Z"},"trusted":true},"execution_count":null,"outputs":[]}]}