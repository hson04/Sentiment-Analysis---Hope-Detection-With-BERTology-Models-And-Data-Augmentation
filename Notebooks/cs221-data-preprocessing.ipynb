{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8639065,"sourceType":"datasetVersion","datasetId":5153528}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"path_train = \"/kaggle/input/dataset-cs221/train_en.csv\"\npath_val = \"/kaggle/input/dataset-cs221/val_en.csv\"\npath_test = \"/kaggle/input/dataset-cs221/test_en.csv\"\npath_test_labeled = \"/kaggle/input/dataset-cs221/test_en_labeled.csv\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-26T08:21:23.473230Z","iopub.execute_input":"2024-06-26T08:21:23.473614Z","iopub.status.idle":"2024-06-26T08:21:23.478672Z","shell.execute_reply.started":"2024-06-26T08:21:23.473585Z","shell.execute_reply":"2024-06-26T08:21:23.477538Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf1 = pd.read_csv(path_train)\ndf2 = pd.read_csv(path_val)\ndf3 = pd.read_csv(path_test)\ndf4 = pd.read_csv(path_test_labeled)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:21:24.019588Z","iopub.execute_input":"2024-06-26T08:21:24.020022Z","iopub.status.idle":"2024-06-26T08:21:24.090953Z","shell.execute_reply.started":"2024-06-26T08:21:24.019988Z","shell.execute_reply":"2024-06-26T08:21:24.089918Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:21:24.219015Z","iopub.execute_input":"2024-06-26T08:21:24.219439Z","iopub.status.idle":"2024-06-26T08:21:24.228138Z","shell.execute_reply.started":"2024-06-26T08:21:24.219408Z","shell.execute_reply":"2024-06-26T08:21:24.226863Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0       #USER# #USER# I'm really liking this project, ...\n1       #USER# Oh shit really? I would hope they'd she...\n2       #USER# Good morning, Bud! ðŸ¥° Another good decis...\n3       i aspire to have the level of delusion to beli...\n4       #USER# #USER# Projects are continuously attack...\n                              ...                        \n6187    ðŸŒŸ: But, it was a great depiction of the main c...\n6188    Because it's brave to outright misappropriate ...\n6189    #USER# They got this one wrong. I'm a devout, ...\n6190    #USER# #USER# Not even close. Myself as many o...\n6191    #USER# ðŸ’¯ agree mate. Started doing this a few ...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Simple Preprocessing","metadata":{}},{"cell_type":"code","source":"import string, re\ndef preprocessing_text(text):    \n    text = text.strip()\n    text = text.translate(text.maketrans('', '', string.punctuation.replace(\"_\",\"\")))\n    text = re.sub('\\\\s+',' ',text).strip()\n    return text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['text']=df1['text'].apply(preprocessing_text)\ndf2['text']=df2['text'].apply(preprocessing_text)\ndf3['text']=df3['text'].apply(preprocessing_text)\ndf4['text']=df4['text'].apply(preprocessing_text)\n\ndf1['text']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.to_csv(\"simple_train_en.csv\", index = False)\ndf2.to_csv(\"simple_val_en.csv\", index = False)\ndf3.to_csv(\"simple_test_en.csv\", index = False)\ndf4.to_csv(\"simple_test_en_labeled.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# More Preprocessing Below (Enhanced):","metadata":{}},{"cell_type":"markdown","source":"# Mini handling methods","metadata":{}},{"cell_type":"code","source":"def removal(text):\n    text = text.replace('#USER#', '')\n    text = text.replace('#URL#', '')\n    text = text.lower()\n    \n    return text\n\ndf1['text']=df1['text'].apply(removal)\ndf2['text']=df2['text'].apply(removal)\ndf3['text']=df3['text'].apply(removal)\ndf4['text']=df4['text'].apply(removal)\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-26T08:16:49.828360Z","iopub.execute_input":"2024-06-26T08:16:49.828750Z","iopub.status.idle":"2024-06-26T08:16:49.866237Z","shell.execute_reply.started":"2024-06-26T08:16:49.828719Z","shell.execute_reply":"2024-06-26T08:16:49.865197Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0         i'm really liking this project, let's work t...\n1        oh shit really? i would hope they'd shed some...\n2        good morning, bud! ðŸ¥° another good decision fr...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    ðŸŒŸ: but, it was a great depiction of the main c...\n6188    because it's brave to outright misappropriate ...\n6189     they got this one wrong. i'm a devout, practi...\n6190      not even close. myself as many others believ...\n6191     ðŸ’¯ agree mate. started doing this a few months...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Lower casing\n","metadata":{}},{"cell_type":"code","source":"#Lower casing\ndef lowercase(text):\n    return text.lower()\n\ndf1['text'] = df1['text'].apply(lowercase)\ndf2['text'] = df2['text'].apply(lowercase)\ndf3['text'] = df3['text'].apply(lowercase)\ndf4['text'] = df4['text'].apply(lowercase)\n\ndf1['text']\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.462352Z","iopub.execute_input":"2024-06-09T12:41:16.462644Z","iopub.status.idle":"2024-06-09T12:41:16.497523Z","shell.execute_reply.started":"2024-06-09T12:41:16.462620Z","shell.execute_reply":"2024-06-09T12:41:16.496372Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"0         i'm really liking this project, let's work t...\n1        oh shit really? i would hope they'd shed some...\n2        good morning, bud! ðŸ¥° another good decision fr...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    ðŸŒŸ: but, it was a great depiction of the main c...\n6188    because it's brave to outright misappropriate ...\n6189     they got this one wrong. i'm a devout, practi...\n6190      not even close. myself as many others believ...\n6191     ðŸ’¯ agree mate. started doing this a few months...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Remove @usename mentions","metadata":{}},{"cell_type":"code","source":"import re\ndef remove_mentions(text):\n    mention_regex = r\"\\@\\w+\"\n    return re.sub(mention_regex, '', text)\n\ndf1['text'] = df1['text'].apply(remove_mentions)\ndf2['text'] = df2['text'].apply(remove_mentions)\ndf3['text'] = df3['text'].apply(remove_mentions)\ndf4['text'] = df4['text'].apply(remove_mentions)\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.500092Z","iopub.execute_input":"2024-06-09T12:41:16.500743Z","iopub.status.idle":"2024-06-09T12:41:16.528957Z","shell.execute_reply.started":"2024-06-09T12:41:16.500707Z","shell.execute_reply":"2024-06-09T12:41:16.527883Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"0         i'm really liking this project, let's work t...\n1        oh shit really? i would hope they'd shed some...\n2        good morning, bud! ðŸ¥° another good decision fr...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    ðŸŒŸ: but, it was a great depiction of the main c...\n6188    because it's brave to outright misappropriate ...\n6189     they got this one wrong. i'm a devout, practi...\n6190      not even close. myself as many others believ...\n6191     ðŸ’¯ agree mate. started doing this a few months...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# import re\n# def remove_mentions(text):\n#     mention_regex = r\"\\@\\w+\"\n#     return re.sub(mention_regex, \"<mention>\", text)\n\n# df1['text'] = df1['text'].apply(remove_mentions)\n# df2['text'] = df2['text'].apply(remove_mentions)\n# df3['text'] = df3['text'].apply(remove_mentions)\n\n# #df1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.530119Z","iopub.execute_input":"2024-06-09T12:41:16.530470Z","iopub.status.idle":"2024-06-09T12:41:16.536174Z","shell.execute_reply.started":"2024-06-09T12:41:16.530444Z","shell.execute_reply":"2024-06-09T12:41:16.535258Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# URL Handling","metadata":{}},{"cell_type":"code","source":"#Removes URL data\ndef remove_url(data):\n    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n    data=url_clean.sub(r'',data)\n    return data\n\ndf1['text']=df1['text'].apply(lambda z: remove_url(z))\ndf2['text']=df2['text'].apply(lambda z: remove_url(z))\ndf3['text']=df3['text'].apply(lambda z: remove_url(z))\ndf4['text']=df4['text'].apply(lambda z: remove_url(z))\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.537331Z","iopub.execute_input":"2024-06-09T12:41:16.537639Z","iopub.status.idle":"2024-06-09T12:41:16.582659Z","shell.execute_reply.started":"2024-06-09T12:41:16.537615Z","shell.execute_reply":"2024-06-09T12:41:16.581545Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"0         i'm really liking this project, let's work t...\n1        oh shit really? i would hope they'd shed some...\n2        good morning, bud! ðŸ¥° another good decision fr...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    ðŸŒŸ: but, it was a great depiction of the main c...\n6188    because it's brave to outright misappropriate ...\n6189     they got this one wrong. i'm a devout, practi...\n6190      not even close. myself as many others believ...\n6191     ðŸ’¯ agree mate. started doing this a few months...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# # Replaces URLs with \"<link>\"\n# def replace_url(data):\n#     url_pattern = r\"https://\\S+|www\\.\\S+\"\n#     return re.sub(url_pattern, \"<link>\", data)\n\n\n# df1['text'] = df1['text'].apply(replace_url)\n# df2['text'] = df2['text'].apply(replace_url)\n# df3['text'] = df3['text'].apply(replace_url)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.583866Z","iopub.execute_input":"2024-06-09T12:41:16.584179Z","iopub.status.idle":"2024-06-09T12:41:16.588652Z","shell.execute_reply.started":"2024-06-09T12:41:16.584155Z","shell.execute_reply":"2024-06-09T12:41:16.587475Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"# Emojies handling\n","metadata":{}},{"cell_type":"code","source":"#Removes Emojis\ndef remove_emoji(data):\n    emoji_clean= re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    data=emoji_clean.sub(r'',data)\n    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n    data=url_clean.sub(r'',data)\n    return data\ndf1['text']=df1['text'].apply(lambda z: remove_emoji(z))\ndf2['text']=df2['text'].apply(lambda z: remove_emoji(z))\ndf3['text']=df3['text'].apply(lambda z: remove_emoji(z))\ndf4['text']=df4['text'].apply(lambda z: remove_emoji(z))\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.591072Z","iopub.execute_input":"2024-06-09T12:41:16.591361Z","iopub.status.idle":"2024-06-09T12:41:16.699757Z","shell.execute_reply.started":"2024-06-09T12:41:16.591337Z","shell.execute_reply":"2024-06-09T12:41:16.698754Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"0         i'm really liking this project, let's work t...\n1        oh shit really? i would hope they'd shed some...\n2        good morning, bud! ðŸ¥° another good decision fr...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    : but, it was a great depiction of the main ch...\n6188    because it's brave to outright misappropriate ...\n6189     they got this one wrong. i'm a devout, practi...\n6190      not even close. myself as many others believ...\n6191      agree mate. started doing this a few months ...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Replace Emoji with <emoji>. NO with ''\nimport re\nimport emoji\n\ndef emojo(text):\n    #text = emoji.demojize(text, language='en').replace(':', ' ')\n    emoji_regex = r\"[^\\u0000-\\uD7FF\\uE000-\\uF8FF\\uFB00-\\uFE0F\\uFEFF-\\uFFFF]\"\n    #return re.sub(emoji_regex, \"<emoji>\", text)\n    return re.sub(emoji_regex, \"\", text)\n\ndf1['text']=df1['text'].apply(lambda z: emojo(z))\ndf2['text']=df2['text'].apply(lambda z: emojo(z))\ndf3['text']=df3['text'].apply(lambda z: emojo(z))\ndf4['text']=df4['text'].apply(lambda z: emojo(z))\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.700863Z","iopub.execute_input":"2024-06-09T12:41:16.701184Z","iopub.status.idle":"2024-06-09T12:41:16.737205Z","shell.execute_reply.started":"2024-06-09T12:41:16.701159Z","shell.execute_reply":"2024-06-09T12:41:16.736233Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"0         i'm really liking this project, let's work t...\n1        oh shit really? i would hope they'd shed some...\n2        good morning, bud!  another good decision fro...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    : but, it was a great depiction of the main ch...\n6188    because it's brave to outright misappropriate ...\n6189     they got this one wrong. i'm a devout, practi...\n6190      not even close. myself as many others believ...\n6191      agree mate. started doing this a few months ...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Full form transformation","metadata":{}},{"cell_type":"code","source":"## In this case, we will be replacing some abbreviated pronouns with full forms (example:\"you've\"->you have\")\ndef remove_abb(data):\n    data = re.sub(r\"he's\", \"he is\", data)\n    data = re.sub(r\"there's\", \"there is\", data)\n    data = re.sub(r\"We're\", \"We are\", data)\n    data = re.sub(r\"That's\", \"That is\", data)\n    data = re.sub(r\"won't\", \"will not\", data)\n    data = re.sub(r\"they're\", \"they are\", data)\n    data = re.sub(r\"Can't\", \"Cannot\", data)\n    data = re.sub(r\"wasn't\", \"was not\", data)\n    data = re.sub(r\"don\\x89Ã›Âªt\", \"do not\", data)\n    data = re.sub(r\"aren't\", \"are not\", data)\n    data = re.sub(r\"isn't\", \"is not\", data)\n    data = re.sub(r\"What's\", \"What is\", data)\n    data = re.sub(r\"haven't\", \"have not\", data)\n    data = re.sub(r\"hasn't\", \"has not\", data)\n    data = re.sub(r\"There's\", \"There is\", data)\n    data = re.sub(r\"He's\", \"He is\", data)\n    data = re.sub(r\"It's\", \"It is\", data)\n    data = re.sub(r\"You're\", \"You are\", data)\n    data = re.sub(r\"I'M\", \"I am\", data)\n    data = re.sub(r\"shouldn't\", \"should not\", data)\n    data = re.sub(r\"wouldn't\", \"would not\", data)\n    data = re.sub(r\"i'm\", \"I am\", data)\n    data = re.sub(r\"I\\x89Ã›Âªm\", \"I am\", data)\n    data = re.sub(r\"I'm\", \"I am\", data)\n    data = re.sub(r\"Isn't\", \"is not\", data)\n    data = re.sub(r\"Here's\", \"Here is\", data)\n    data = re.sub(r\"you've\", \"you have\", data)\n    data = re.sub(r\"you\\x89Ã›Âªve\", \"you have\", data)\n    data = re.sub(r\"we're\", \"we are\", data)\n    data = re.sub(r\"what's\", \"what is\", data)\n    data = re.sub(r\"couldn't\", \"could not\", data)\n    data = re.sub(r\"we've\", \"we have\", data)\n    data = re.sub(r\"it\\x89Ã›Âªs\", \"it is\", data)\n    data = re.sub(r\"doesn\\x89Ã›Âªt\", \"does not\", data)\n    data = re.sub(r\"It\\x89Ã›Âªs\", \"It is\", data)\n    data = re.sub(r\"Here\\x89Ã›Âªs\", \"Here is\", data)\n    data = re.sub(r\"who's\", \"who is\", data)\n    data = re.sub(r\"I\\x89Ã›Âªve\", \"I have\", data)\n    data = re.sub(r\"y'all\", \"you all\", data)\n    data = re.sub(r\"can\\x89Ã›Âªt\", \"cannot\", data)\n    data = re.sub(r\"would've\", \"would have\", data)\n    data = re.sub(r\"it'll\", \"it will\", data)\n    data = re.sub(r\"we'll\", \"we will\", data)\n    data = re.sub(r\"wouldn\\x89Ã›Âªt\", \"would not\", data)\n    data = re.sub(r\"We've\", \"We have\", data)\n    data = re.sub(r\"he'll\", \"he will\", data)\n    data = re.sub(r\"Y'all\", \"You all\", data)\n    data = re.sub(r\"Weren't\", \"Were not\", data)\n    data = re.sub(r\"Didn't\", \"Did not\", data)\n    data = re.sub(r\"they'll\", \"they will\", data)\n    data = re.sub(r\"they'd\", \"they would\", data)\n    data = re.sub(r\"DON'T\", \"DO NOT\", data)\n    data = re.sub(r\"That\\x89Ã›Âªs\", \"That is\", data)\n    data = re.sub(r\"they've\", \"they have\", data)\n    data = re.sub(r\"i'd\", \"I would\", data)\n    data = re.sub(r\"should've\", \"should have\", data)\n    data = re.sub(r\"You\\x89Ã›Âªre\", \"You are\", data)\n    data = re.sub(r\"where's\", \"where is\", data)\n    data = re.sub(r\"Don\\x89Ã›Âªt\", \"Do not\", data)\n    data = re.sub(r\"we'd\", \"we would\", data)\n    data = re.sub(r\"i'll\", \"I will\", data)\n    data = re.sub(r\"weren't\", \"were not\", data)\n    data = re.sub(r\"They're\", \"They are\", data)\n    data = re.sub(r\"Can\\x89Ã›Âªt\", \"Cannot\", data)\n    data = re.sub(r\"you\\x89Ã›Âªll\", \"you will\", data)\n    data = re.sub(r\"I\\x89Ã›Âªd\", \"I would\", data)\n    data = re.sub(r\"let's\", \"let us\", data)\n    data = re.sub(r\"it's\", \"it is\", data)\n    data = re.sub(r\"can't\", \"cannot\", data)\n    data = re.sub(r\"don't\", \"do not\", data)\n    data = re.sub(r\"you're\", \"you are\", data)\n    data = re.sub(r\"i've\", \"I have\", data)\n    data = re.sub(r\"that's\", \"that is\", data)\n    data = re.sub(r\"i'll\", \"I will\", data)\n    data = re.sub(r\"doesn't\", \"does not\",data)\n    data = re.sub(r\"i'd\", \"I would\", data)\n    data = re.sub(r\"didn't\", \"did not\", data)\n    data = re.sub(r\"ain't\", \"am not\", data)\n    data = re.sub(r\"you'll\", \"you will\", data)\n    data = re.sub(r\"I've\", \"I have\", data)\n    data = re.sub(r\"Don't\", \"do not\", data)\n    data = re.sub(r\"I'll\", \"I will\", data)\n    data = re.sub(r\"I'd\", \"I would\", data)\n    data = re.sub(r\"Let's\", \"Let us\", data)\n    data = re.sub(r\"you'd\", \"You would\", data)\n    data = re.sub(r\"It's\", \"It is\", data)\n    data = re.sub(r\"Ain't\", \"am not\", data)\n    data = re.sub(r\"Haven't\", \"Have not\", data)\n    data = re.sub(r\"Could've\", \"Could have\", data)\n    data = re.sub(r\"youve\", \"you have\", data)  \n    data = re.sub(r\"donÃ¥Â«t\", \"do not\", data)  \n    \n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.739561Z","iopub.execute_input":"2024-06-09T12:41:16.739876Z","iopub.status.idle":"2024-06-09T12:41:16.775467Z","shell.execute_reply.started":"2024-06-09T12:41:16.739850Z","shell.execute_reply":"2024-06-09T12:41:16.774376Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"df1['text']=df1['text'].apply(lambda z: remove_abb(z))\ndf2['text']=df2['text'].apply(lambda z: remove_abb(z))\ndf3['text']=df3['text'].apply(lambda z: remove_abb(z))\ndf4['text']=df4['text'].apply(lambda z: remove_abb(z))\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:16.776657Z","iopub.execute_input":"2024-06-09T12:41:16.776953Z","iopub.status.idle":"2024-06-09T12:41:17.758369Z","shell.execute_reply.started":"2024-06-09T12:41:16.776923Z","shell.execute_reply":"2024-06-09T12:41:17.757385Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"0         I am really liking this project, let us work...\n1        oh shit really? i would hope they would shed ...\n2        good morning, bud!  another good decision fro...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187    : but, it was a great depiction of the main ch...\n6188    because it is brave to outright misappropriate...\n6189     they got this one wrong. I am a devout, pract...\n6190      not even close. myself as many others believ...\n6191      agree mate. started doing this a few months ...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Remove Punctuations & others","metadata":{}},{"cell_type":"code","source":"import re\n#Removes Punctuations\ndef remove_punctuations(data):\n    punct_tag=re.compile(r'[^\\w\\s]')\n    data=punct_tag.sub(r'',data)\n    return data\n\ndf1['text']=df1['text'].apply(lambda z: remove_punctuations(z))\ndf2['text']=df2['text'].apply(lambda z: remove_punctuations(z))\ndf3['text']=df3['text'].apply(lambda z: remove_punctuations(z))\ndf4['text']=df4['text'].apply(lambda z: remove_punctuations(z))\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:17.759432Z","iopub.execute_input":"2024-06-09T12:41:17.759706Z","iopub.status.idle":"2024-06-09T12:41:17.826477Z","shell.execute_reply.started":"2024-06-09T12:41:17.759683Z","shell.execute_reply":"2024-06-09T12:41:17.825516Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"0         I am really liking this project let us work ...\n1        oh shit really i would hope they would shed s...\n2        good morning bud  another good decision from ...\n3       i aspire to have the level of delusion to beli...\n4         projects are continuously attacked by hacker...\n                              ...                        \n6187     but it was a great depiction of the main char...\n6188    because it is brave to outright misappropriate...\n6189     they got this one wrong I am a devout practic...\n6190      not even close myself as many others believe...\n6191      agree mate started doing this a few months a...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Lemmatization","metadata":{}},{"cell_type":"code","source":"# Downloading data\nimport nltk\nimport subprocess\n\n# Download and unzip wordnet\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n\n# Now you can import the NLTK resources as usual\nfrom nltk.corpus import wordnet","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:17.827657Z","iopub.execute_input":"2024-06-09T12:41:17.827950Z","iopub.status.idle":"2024-06-09T12:41:17.862559Z","shell.execute_reply.started":"2024-06-09T12:41:17.827926Z","shell.execute_reply":"2024-06-09T12:41:17.861609Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /kaggle/working/corpora/wordnet.zip\n","output_type":"stream"},{"name":"stderr","text":"replace /kaggle/working/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\n\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag\n\ndef lemmatize_text_pos(text):\n    lemmatizer = WordNetLemmatizer()\n    punctuations = \"?:!.,\"\n\n    words = word_tokenize(text)\n    words = [word for word in words if word not in punctuations]\n\n    lemmatized_text = []\n    for word in words:\n        lemma = lemmatizer.lemmatize(word, pos=\"v\")\n        lemmatized_text.append(lemma)\n    \n    return \" \".join(lemmatized_text)\n\ndf1['text'] = df1['text'].apply(lemmatize_text_pos)\ndf2['text'] = df2['text'].apply(lemmatize_text_pos)\ndf3['text'] = df3['text'].apply(lemmatize_text_pos)\ndf4['text'] = df4['text'].apply(lemmatize_text_pos)\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:17.863799Z","iopub.execute_input":"2024-06-09T12:41:17.864177Z","iopub.status.idle":"2024-06-09T12:41:21.082817Z","shell.execute_reply.started":"2024-06-09T12:41:17.864150Z","shell.execute_reply":"2024-06-09T12:41:21.081878Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"0       I be really like this project let us work toge...\n1       oh shit really i would hope they would shed so...\n2       good morning bud another good decision from sc...\n3       i aspire to have the level of delusion to beli...\n4       project be continuously attack by hackers that...\n                              ...                        \n6187    but it be a great depiction of the main charac...\n6188    because it be brave to outright misappropriate...\n6189    they get this one wrong I be a devout practice...\n6190    not even close myself as many others believe b...\n6191    agree mate start do this a few months ago when...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Stopwords remove","metadata":{}},{"cell_type":"code","source":"# # Stopword removal\n# from nltk.corpus import stopwords\n\n\n# def remove_stopwords(text, stopword_list=None):\n#     if stopword_list is None:\n#         stopword_list = stopwords.words('english')\n        \n#     words = word_tokenize(text)\n    \n#     filtered_words = [word for word in words if word not in stopword_list]\n    \n#     return \" \".join(filtered_words)\n\n# df1['text']=df1['text'].apply(lambda z: remove_stopwords(z))\n# df2['text']=df2['text'].apply(lambda z: remove_stopwords(z))\n# df3['text']=df3['text'].apply(lambda z: remove_stopwords(z))\n# df4['text']=df4['text'].apply(lambda z: remove_stopwords(z))\n\n# df1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:21.085922Z","iopub.execute_input":"2024-06-09T12:41:21.086677Z","iopub.status.idle":"2024-06-09T12:41:21.090682Z","shell.execute_reply.started":"2024-06-09T12:41:21.086648Z","shell.execute_reply":"2024-06-09T12:41:21.089771Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"# Stemming\n","metadata":{}},{"cell_type":"code","source":"# # Stemming:\n\n# from nltk.tokenize import sent_tokenize, word_tokenize\n# from nltk.stem import PorterStemmer  # Import PorterStemmer class\n\n# def stem_sentence(sentence):\n#     \"\"\"Stems a given sentence using Porter stemmer.\n\n#     Args:\n#         sentence (str): The sentence to be stemmed.\n\n#     Returns:\n#         str: The stemmed sentence with spaces between words.\n#     \"\"\"\n\n#     stemmer = PorterStemmer()  # Create a single stemmer object\n#     stemmed_words = []\n#     for word in word_tokenize(sentence):\n#         stemmed_words.append(stemmer.stem(word))\n#     return \" \".join(stemmed_words)\n\n# # Apply stemming to 'text' columns of DataFrames\n# df1['text'] = df1['text'].apply(stem_sentence)\n# df2['text'] = df2['text'].apply(stem_sentence)\n# df3['text'] = df3['text'].apply(stem_sentence)\n# df4['text'] = df4['text'].apply(stem_sentence)\n\n# df1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:21.092101Z","iopub.execute_input":"2024-06-09T12:41:21.092747Z","iopub.status.idle":"2024-06-09T12:41:21.099612Z","shell.execute_reply.started":"2024-06-09T12:41:21.092712Z","shell.execute_reply":"2024-06-09T12:41:21.098759Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"# Lower Casing","metadata":{}},{"cell_type":"code","source":"#Lower casing\ndef lowercase(text):\n    return text.lower()\n\ndf1['text'] = df1['text'].apply(lowercase)\ndf2['text'] = df2['text'].apply(lowercase)\ndf3['text'] = df3['text'].apply(lowercase)\ndf4['text'] = df4['text'].apply(lowercase)\n\n\ndf1['text']","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:41:21.100751Z","iopub.execute_input":"2024-06-09T12:41:21.101054Z","iopub.status.idle":"2024-06-09T12:41:21.123758Z","shell.execute_reply.started":"2024-06-09T12:41:21.101005Z","shell.execute_reply":"2024-06-09T12:41:21.122874Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"0       i be really like this project let us work toge...\n1       oh shit really i would hope they would shed so...\n2       good morning bud another good decision from sc...\n3       i aspire to have the level of delusion to beli...\n4       project be continuously attack by hackers that...\n                              ...                        \n6187    but it be a great depiction of the main charac...\n6188    because it be brave to outright misappropriate...\n6189    they get this one wrong i be a devout practice...\n6190    not even close myself as many others believe b...\n6191    agree mate start do this a few months ago when...\nName: text, Length: 6192, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"# Saving datasets","metadata":{}},{"cell_type":"code","source":"df1.to_csv(\"final_train_en.csv\", index = False)\ndf2.to_csv(\"final_val_en.csv\", index = False)\ndf3.to_csv(\"final_test_en.csv\", index = False)\ndf4.to_csv(\"final_test_en_labeled.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T12:42:55.064206Z","iopub.execute_input":"2024-06-09T12:42:55.065161Z","iopub.status.idle":"2024-06-09T12:42:55.128013Z","shell.execute_reply.started":"2024-06-09T12:42:55.065126Z","shell.execute_reply":"2024-06-09T12:42:55.127002Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}